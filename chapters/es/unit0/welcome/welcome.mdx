# Bienvenid@ al curso comunitario de Visi贸n Artificial

Querido participante, 

Bienvenid@ al **curso de visi贸n artificial impulsado por la comunidad de **. El campo de la visi贸n artificial est谩 revolucionando el mundo de muchas maneras, desde el desbloqueo de tel茅fonos m贸viles a trav茅s de sistemas de reconocimiento facial, pasando por el an谩lisis de im谩genes m茅dicas para la detecci贸n de enfermedades, hasta la vigilancia de la vida salvaje o la generaci贸n de nuevas im谩genes. Juntos, nos sumergiremos en el fascinante mundo de la visi贸n artificial!

En este curso cubriremos todo lo relacionado con visi贸n artificial, desde los conceptos m谩s b谩sicos hasta los 煤ltimos avances en este campo. Est谩 estructurado y dise帽ado para incluir temas fundacionales, de tal manera que sea accesible y agradable para todo el mundo. Nos encanta que hayas decidido acompa帽arnos en este fant谩stico viaje!

En esta p谩gina encontrar谩s informaci贸n sobre c贸mo unirte a la comunidad de participantes, subir tus archivos, obtener la certificaci贸n, y otros detalles sobre el curso!

## Tareas 

Para obtener la certificaci贸n al terminar el curso, tendr谩s que realizar las siguientes tareas:

1. Entrenar/afinar un modelo
2. Crear una aplicaci贸n y subirla/hostearla en un espacio de Hugging Face (Hugging Face Spaces)

### Entrenar/Afinar un modelo

Para ello, encontrar谩s notebooks debajo de la secci贸n de Notebooks/Vision Transformers. De momento, existen notebooks para detecci贸n de objetos, segmentaci贸n de im谩genes y clasificaci贸n de im谩genes. Puedes tanto entrenar un modelo en un dataset que ya exista en el repositorio de  o subir un dataset a un repositorio privado y entrenar un modelo sobre ese mismo dataset.

El repositorio de modelos necesita contar con lo siguiente:


1. Una tarjeta de modelo rellenada correctamente, puedes dirigirte [aqu铆 para m谩s informaci贸n sobre como rellenarla](https://huggingface.co/docs/hub/en/model-cards).
2. Si has entrenado un modelo utilizando la librer铆a de transformers y lo has subido al repositorio de HF, la tarjeta del modelo se generar谩 autom谩ticamente. En ese caso, edita la tarjeta y rellena los detalles que faltan.
3. A帽ade el ID del dataset a la tarjeta del modelo para enlazar el repositorio del modelo al repositorio del dataset.

### Creando un Espacio

En esta parte de la tarea construir谩s una aplicaci贸n basada en Gradio para tu modelo de visi贸n artificial, la cual compartir谩s posteriormente en los espacios de . Explora m谩s info sobre estas tareas en los siguientes recursos:

- [Empezando con Gradio](https://huggingface.co/learn/nlp-course/chapter9/1?fw=pt#introduction-to-gradio)
- [C贸mo compartir tu aplicaci贸n en los espacios de ](https://huggingface.co/learn/nlp-course/chapter9/4?fw=pt)

## Certificaci贸n 

Una vez que hayas finalizado las tareas de Entrenar/Afinar un modelo y crear un espacio, por favor, rellena el [formulario](https://forms.gle/isiVSw59oiiHP6pN9) con tu nombre, correo, y links a los repositorios de tu modelo y espacio para recibir tu certificado.

## nete a la comunidad!

Te invitamos a ser parte de [nuestra comunidad activa y amistosa en Discord](http://hf.co/join/discord), donde naci贸 este curso y donde podr谩s encontrar conversaciones fascinantes e intereses comunes con otros miembros. All铆 encontrar谩s otros participantes con los que intercambiar ideas y recursos. Es tu fuente para colaborar con otros, recibir feedback y preguntar dudas!

Tambi茅n es una manera de motivarte para seguir el curso. Unirse a nuestra comunidad es una manera estupenda de mantenerse al d铆a. Qui茅n sabe que ser谩 lo pr贸ximo que construiremos juntos?

Mientras la Inteligencia Artificial contin煤a avanzando, tambi茅n lo hace la calidad de nuestras discusiones y la diversidad de las perspectivas dentro de nuestra comunidad. Al convertirte en miembro, tendr谩s la oportunidad de conectar con otros participantes del curso, intercambiar ideas, y colaborar con otros. Adem谩s, los creadores y colaboradores de este curso est谩n atentos y activos en Discord, y podr铆an ayudarte en caso de que lo necesitases. nete ahora!

## Canales de Visi贸n Artificial

Hay muchos canales en nuestro servidor de Discord, cada uno dedicado a temas distintos. Te encontrar谩s a gente hablando de art铆culos acad茅micos, organizando eventos, compartiendo sus proyectos e ideas, compartiendo ideas y haciendo brainstorming y mucho m谩s.

Como participante del curso de Visi贸n Artificial, puede que encuentres especialmente relevantes los siguientes canales:

- `#computer-vision`: un canal general para todo lo relacionado con Visi贸n Artificial
- `#3d`: un canal para hablar de Visi贸n Artificial espec铆ficamente aplicada a Visi贸n Artificial en 3D.

Si est谩s interesado en Inteligencia Artificial Generativa, tambi茅n te invitamos a que te unas a todos los canales relacionados con modelos de Difusi贸n: `#core-announcements`, `#discussions`, `#dev-discussions`, y `#i-made-this`.

## Qu茅 aprender谩s

Este curso est谩 compuesto de teor铆a, tutoriales pr谩cticos y retos fascinantes.

- **Parte de teor铆a**: Esta secci贸n cubre los principios te贸ricos de Visi贸n Artificial, todos ellos explicados en detalle con ejemplos pr谩cticos.
- **Tutoriales pr谩cticos**: Aprender谩s c贸mo entrenar y aplicar modelos relevantes de Visi贸n Artificial utilizando notebooks de Google Collab.

A lo largo de este curso, cubriremos todo, desde los conceptos b谩sicos a los 煤ltimos avances en Visi贸n Artificial. Est谩 estructurado de manera que cubre varios temas fundacionales, d谩ndote una perspectiva y conocimiento en profundidad de por qu茅 el uso de t茅cnicas de Visi贸n Artificial tiene tanto impacto en el mundo real.

## Prerrequisitos

Antes de empezar el curso, aseg煤rate de contar con algo de experiencia programando en Python y conocer conceptos relacionados con transformers, machine learning y redes neuronales. Si cualquiera de estos conceptos es nuevo para ti, quiz谩 sea bueno que repases [la primera unidad del curso de NLP de Hugging Face](https://huggingface.co/learn/nlp-course/chapter1/3?fw=pt). Tener un buen conocimiento de t茅cnicas de preprocesamiento y operaciones matem谩ticas es bueno, no son necesariamente prerrequisitos para este curso.

## Estructura del curso

El curso est谩 organizado en varias unidades, las cuales van desde lo fundamental hasta un repaso profundo de los modelos m谩s avanzados (state-of-the-art models o SOTA):

- **Unidad 1 - Conceptos fundamentales de Visi贸n Artificial** : esta unidad cubre los conceptos esenciales para empezar con visi贸n artificial: la necesidad para la existencia de visi贸n artificial, los conceptos b谩sicos de este campo y sus aplicaciones. Tambi茅n se exploran aspectos como la formaci贸n, el preprocesamiento y otros conceptos b谩sicos del tratamiento de im谩genes, as铆 como aspectos clave de la extracci贸n de caracter铆sticas.
- **Unidad 2 - Redes Neuronales Convolucionales (CNNs por sus siglas en ingl茅s)** : explora el mundo de las CNNs, entendiendo su arquitectura general, conceptos clave y los modelos pre-entrenados m谩s relevantes. Aprende como aplicar conocimiento por transferencia (transfer learning) y afinar este tipo de modelos pre-entrenados para adaptarlos a tareas espec铆ficas. 
- **Unidad 3 - Transformers para Visi贸n (Vision Transformers o ViTs por sus siglas en ingl茅s)** : explora la arquitectura de transformers en un contexto de visi贸n artificial y aprende como se comparan con las redes convolucionales. Aprende sobre los transformers de visi贸n m谩s utilizados como Swin, DETR o CVT, junto con t茅cnicas de transfer learning y el afinamiento de dichos modelos.
- **Unidad 4 - Modelos multimodales** : entiende la mezcla entre texto y visi贸n a trav茅s de la exploraci贸n de tareas multimodales como imagen-a-texto y texto-a-imagen. Estudia modelos como CLIP y aquellos relacionados (GroupViT, BLIPM, Owl-VIT), y domina las t茅cnicas de transfer learning para tareas multimodales.
- **Unidad 5 - Modelos generativos** : explora modelos generativos, incluyendo GANs (redes generativas adversativas), VAEs (autoencoders variacionales) y modelos de Difusi贸n. Aprende sus diferencias y aplicaciones en tareas como texto-a-imagen, imagen-a-imagen e inpainting (restauraci贸n o generaci贸n de partes en una imagen).
- **Unidad 6 - Tareas b谩sicas de Visi贸n Artificial** : cubriremos tareas fundamentales como clasificaci贸n de im谩genes, detecci贸n de objetos y segmentaci贸n de im谩genes, y los modelos m谩s habituales utilizados para estas tareas (YOLO, SAM). Aprender谩s sobre las m茅tricas de evaluaci贸n y las aplicaciones reales de estas tareas. 
- **Unidad 7 - Video y procesamiento de video** : examinaremos las caracter铆sticas de los videos, el rol del procesamiento de video y los retos que existen en comparaci贸n al procesamiento de im谩genes. Exploraremos continuidad temporal, estimaci贸n del movimiento y las aplicaciones pr谩cticas del procesamiento de video.
- **Unidad 8 - Visi贸n para 3D, Renderizaci贸n y reconstrucci贸n de escenas** : explora las complejidades de la visi贸n en tres dimensiones, explorando conceptos como Nerf y GQN para renderizaci贸n y reconstrucci贸n de escenas. Tambi茅n aprender谩s sobre los retos y aplicaciones de la visi贸n artificial en 3D y como provee de una perspectiva con incluso mayor informaci贸n espacial.
- **Unidad 9 - Optimizaci贸n de modelos** : explora los aspectos cr铆ticos de la optimizaci贸n de modelos. Cubriremos t茅cnicas como compresi贸n de modelos, consideraciones a la hora del despliegue y, por 煤ltimo, el uso de herramientas y frameworks. Se incluyen temas como destilaci贸n (distillation), poda (pruning) y TinyML para un despliegue de modelos eficiente.
- **Unidad 10 - Creaci贸n de datos sint茅ticos** : descubre la importancia de la creaci贸n de datos sint茅ticos utilizando modelos generativos. Explora m茅todos como puntos de nubes y modelos de Difusi贸n e investiga datasets sint茅ticos relevantes y sus aplicaciones en visi贸n artificial.
- **Unidad 11 - Visi贸n Artificial de Zero Shot** : entra en el reino del aprendizaje zero-shot en visi贸n artificial, cubriendo aspectos de generalizaci贸n, transfer learning y sus aplicaciones en tareas como reconocimiento de zero-shot y segmentaci贸n de im谩genes. Explora la relaci贸n entre el aprendizaje zero-shot y transfer learning de manera transversal en distintas 谩reas de Visi贸n Artificial.
- **Unidad 12 - tica y sesgo en Visi贸n Artificial** : entiende las consideraciones 茅ticas espec铆ficas a Visi贸n Artificial. Explora por qu茅 la 茅tica importa en Visi贸n Artificial, c贸mo los sesgos pueden existir en modelos de Inteligencia Artificial y los tipos de sesgos que prevalecen en estos campos. Aprende c贸mo evaluar y mitigar el sesgo, siempre enfatizando el desarrollo y despliegue responsable de tecnolog铆as de Inteligencia Artificial.
- **Unidad 13 - Futuro y tendencias emergentes** : explora las tendencias actuales y las arquitecturas emergentes. Entra en enfoques novedosos como las Redes Retentiva, Hiera, Hyena, I-JEPA y los modelos de visi贸n Retentivos.

## Conoce a nuestro equipo

Este curso est谩 hecho por la Comunidad de Hugging Face con ! nete a nosotros a帽adiendo tu contribuci贸n [en GitHub](https://github.com/johko/computer-vision-course).
Nuestra meta era crear un curso de visi贸n artificial que es f谩cil para principiantes y que se pueda utilizar como un recurso para otros. M谩s de 60 personas de todo el mundo han unido sus fuerzas para que este proyecto pasase. Aqu铆 les damos cr茅dito:

**Unidad 1 - Conceptos fundamentales de Visi贸n Artificial**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Ameed Taylor](https://github.com/atayloraerospace), [Sergio Paniego](https://github.com/sergiopaniego)
- Escritores: [Seshu Pavan Mutyala](https://github.com/seshupavan), [Isabella Bicalho-Frazeto](https://github.com/bellabf), [Aman Kapoor](https://github.com/aman06012003), [Tiago Comassetto Fr贸es](https://github.com/froestiago), [Aditya Mishra](https://github.com/adityaiiitr), [Kerem Delikoyun](https://github.com/krmdel), [Ker Lee Yap](https://github.com/klyap), [Kathy Fahnline](https://github.com/kfahn22), [Ameed Taylor](https://github.com/atayloraerospace)

**Unidad 2 - Redes Neuronales Convolucionales (CNNs)**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Mohammed Hamdy](https://github.com/mmhamdy), [Sezan](https://github.com/sezan92), [Joshua Adrian Cahyono](https://github.com/JvThunder), [Murtaza Nazir](https://github.com/themurtazanazir), [Albert Kao](https://github.com/albertkao227), [Sitam Meur](https://github.com/sitamgithub-MSIT), [Antonis Stellas](https://github.com/AntonisCSt), [Sergio Paniego](https://github.com/sergiopaniego)
- Escritores: [Emre Albayrak](https://github.com/emre570), [Caroline Shamiso Chitongo](https://github.com/ShamieCC), [Sezan](https://github.com/sezan92), [Joshua Adrian Cahyono](https://github.com/JvThunder), [Murtaza Nazir](https://github.com/themurtazanazir), [Albert Kao](https://github.com/albertkao227), [Isabella Bicalho-Frazeto](https://github.com/bellabf), [Aman Kapoor](https://github.com/aman06012003), [Sitam Meur](https://github.com/sitamgithub-MSIT)

**Unidad 3 - Transformers para Visi贸n (ViTs)** 

- Revisores: [Ratan Prasad](https://github.com/ratan), [Mohammed Hamdy](https://github.com/mmhamdy), [Ameed Taylor](https://github.com/atayloraerospace), [Sezan](https://github.com/sezan92)
- Escritores: [Surya Guthikonda](https://github.com/SuryaKrishna02), [Ker Lee Yap](https://github.com/klyap), [Anindyadeep Sannigrahi](https://bento.me/anindyadeep), [Celina Hanouti](https://github.com/hanouticelina), [Malcolm Krolick](https://github.com/Mkrolick), [Alvin Li](https://github.com/alvanli), [Shreyas Daniel Gaddam](https://shreydan.github.io), [Anthony Susevski](https://github.com/asusevski), [Alan Ahmet](https://github.com/alanahmet), [Ghassen Fatnassi](https://github.com/ghassen-fatnassi)

**Unidad 4 - Modelos multimodales**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Snehil Sanyal](https://github.com/snehilsanyal), [Mohammed Hamdy](https://github.com/mmhamdy), [Charchit Sharma](https://github.com/charchit7), [Ameed Taylor](https://github.com/atayloraerospace), [Isabella Bicalho-Frazeto](https://github.com/bellabf)
- Escritores: [Snehil Sanyal](https://github.com/snehilsanyal), [Surya Guthikonda](https://github.com/SuryaKrishna02), [Mateusz Dziemian](https://github.com/mattmdjaga), [Charchit Sharma](https://github.com/charchit7), [Evstifeev Stepan](https://github.com/minemile), [Jeremy Kespite](https://github.com/jeremy-k3/), [Isabella Bicalho-Frazeto](https://github.com/bellabf), [Pedro Gabriel Gengo Lourenco](https://github.com/pedrogengo)

**Unidad 5 - Modelos generativos** 

- Revisores: [Ratan Prasad](https://github.com/ratan), [William Bonvini](https://github.com/WilliamBonvini), [Mohammed Hamdy](https://github.com/mmhamdy), [Ameed Taylor](https://github.com/atayloraerospace)-
- Escritores: [Jeronim Matijevi](github.com/jere357), [Mateusz Dziemian](https://github.com/mattmdjaga), [Charchit Sharma](https://github.com/charchit7), [Muhammad Waseem](https://github.com/hwaseem04)

**Unidad 6 - Tareas b谩sicas de Visi贸n Artificial** 

- Revisores: [Adhi Setiawan](https://github.com/adhiiisetiawan)
- Escritores: [Adhi Setiawan](https://github.com/adhiiisetiawan), [Bastien Pou毛ssel](https://github.com/Skower)

**Unidad 7 - Video y procesamiento de video**

- Revisores: [Ameed Taylor](https://github.com/atayloraerospace), [Isabella Bicalho-Frazeto](https://github.com/bellabf)
- Escritores: [Diwakar Basnet](https://github.com/DiwakarBasnet), [Chulhwa Han](https://github.com/cjfghk5697), [Woojun Jung](https://github.com/jungnerd), [Jiwook Han](https://github.com/mreraser), [Mingi Kim](https://github.com/1kmmk1)

**Unidad 8 - Visi贸n para 3D, Renderizaci贸n y reconstrucci贸n de escenas** 

- Revisores: [Ratan Prasad](https://github.com/ratan), [William Bonvini](https://github.com/WilliamBonvini), [Mohammed Hamdy](https://github.com/mmhamdy), [Adhi Setiawan](https://github.com/adhiiisetiawan), [Ameed Taylor](https://github.com/atayloraerospace0)
- Escritores: [John Fozard](https://github.com/jfozard), [Vasu Gupta](https://github.com/vasugupta9), [Psetinek](https://github.com/psetinek)

**Unidad 9 - Optimizaci贸n de modelos**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Mohammed Hamdy](https://github.com/mmhamdy), [Adhi Setiawan](https://github.com/adhiiisetiawan), [Ameed Taylor](https://github.com/atayloraerospace)
- Escritores: [Adhi Setiawan](https://github.com/adhiiisetiawan)

**Unidad 10 - Creaci贸n de datos sint茅ticos**

- Revisores: [Mohammed Hamdy](https://github.com/mmhamdy), [Ameed Taylor](https://github.com/atayloraerospace), [Bhavesh Misra](https://github.com/Zekrom-7780)
- Escritores: [William Bonvini](https://github.com/WilliamBonvini), [Alper Balbay](https://github.com/alperiox), [Madhav Kumar](https://github.com/miniMaddy), [Bhavesh Misra](https://github.com/Zekrom-7780), [Kathy Fahnline](https://github.com/kfahn22)

**Unidad 11 - Visi贸n Artificial de Zero Shot**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Mohammed Hamdy](https://github.com/mmhamdy), [Albert Kao](https://github.com/albertkao227), [Isabella Bicalho-Frazeto](https://github.com/bellabf)
- Escritores: [Mohammed Hamdy](https://github.com/mmhamdy), [Albert Kao](https://github.com/albertkao227)

**Unidad 12 - tica y sesgo en Visi贸n Artificial**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Mohammed Hamdy](https://github.com/mmhamdy), [Charchit Sharma](https://github.com/charchit7), [Adhi Setiawan](https://github.com/adhiiisetiawan), [Ameed Taylor](https://github.com/atayloraerospace), [Bhavesh Misra](https://github.com/Zekrom-7780)
- Escritores: [Snehil Sanyal](https://github.com/snehilsanyal), [Bhavesh Misra](https://github.com/Zekrom-7780)

**Unidad 13 - Futuro y tendencias emergentes**

- Revisores: [Ratan Prasad](https://github.com/ratan), [Ameed Taylor](https://github.com/atayloraerospace), [Mohammed Hamdy](https://github.com/mmhamdy)
- Escritores: [Farros Alferro](https://github.com/farrosalferro), [Mohammed Hamdy](https://github.com/mmhamdy), [Louis Ulmer](https://github.com/lulmer), [Dario Wisznewer](https://github.com/dariowsz), [gonzachiar](https://github.com/gonzachiar)

**Equipo de organizaci贸n**
[Merve Noyan](https://github.com/merveenoyan), [Adam Molnar](https://github.com/lunarflu), [Johannes Kolbe](https://github.com/johko)

Nos encanta tenerte aqu铆, vamos a empezar!
